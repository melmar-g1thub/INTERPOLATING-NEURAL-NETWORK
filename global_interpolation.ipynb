{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1p+uwH7SU7XJwcZ2ZRiAW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Once a model that performs as hoped is found, the whole goal of the interpolation nn is interpolating from a tabulated EoS of Neutron Stars, where the known x variables are temperature (T) and baryon number (n_b) and the y variables are pressure (P) and Entropy (S).\n",
        "\n",
        "We know the true values of both the x and y variables (tabulated EoS in compose archive). To prove that the interpolating algorithm works good, we stick to a small region of the range and perform local interpolation, taking (x_1, x_3) that we do know and interpolating y_2 for x_2, from the test set."
      ],
      "metadata": {
        "id": "onu5mt5Lwcu2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xARTwgmEuhj"
      },
      "source": [
        "### INTERPOLATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CEnNfpVlN2M"
      },
      "source": [
        "1. Select Known Points:\n",
        "Let’s assume we have points (T1, n1) and (T3, n3) that we know, where (T2, n2) will be the intermediate point. (T2, n2) need to be defined within the range of the known points.\n",
        "\n",
        "2. Interpolation Procedure\n",
        "Treat the prediction for (T2, n2) as an unknown during the actual interpolation process. During this phase, we use the model to predict (P2) and (S2).\n",
        "\n",
        "3. Evaluation\n",
        "Calculate the difference between predicted (P2) and (S2) from the model and the exact known values from the tabulated EoS. Metrics like Mean Absolute Error (MAE) or Mean Squared Error (MSE) to quantify how close the interpolated values are to the actual known values."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for performing inverse transform to predictions to get physical values\n",
        "def inv_log_scaled(values, scaler):\n",
        "    real_val = scaler.inverse_transform(np.array(values).reshape(-1, 1)).flatten()\n",
        "    physical_val = 10**real_val\n",
        "    return physical_val\n",
        "\n",
        "# Function to get triplet indices\n",
        "def get_interpolation_indices(center_index, data_length, gap):\n",
        "    idx1 = center_index - gap\n",
        "    idx3 = center_index + gap\n",
        "    if idx1 < 0 or idx3 >= data_length:\n",
        "        return None\n",
        "    return idx1, center_index, idx3\n",
        "\n",
        "# Function to load activation from string\n",
        "def load_activation_fn(activation_str):\n",
        "    activation_map = {\n",
        "        \"ReLU\": nn.ReLU,\n",
        "        \"LeakyReLU\": nn.LeakyReLU,\n",
        "        \"SiLU\": nn.SiLU\n",
        "    }\n",
        "\n",
        "    if \"LeakyReLU\" in activation_str:\n",
        "        return activation_map[\"LeakyReLU\"]\n",
        "    elif \"ReLU\" in activation_str:\n",
        "        return activation_map[\"ReLU\"]\n",
        "    elif \"SiLU\" in activation_str:\n",
        "        return activation_map[\"SiLU\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Activation function '{activation_str}' not recognized.\")"
      ],
      "metadata": {
        "id": "GXZ0rD6EmRol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B30207s6xoYl"
      },
      "outputs": [],
      "source": [
        "#######################################################\n",
        "# NN INTERPOLATION\n",
        "#######################################################\n",
        "def interpolation_test_nn(model, inputs_set, outputs_set, scaler_P, scaler_S, device, indices, save_dir, gap):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    metrics = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, center_index in enumerate(indices):\n",
        "        idx1, idx2, idx3 = get_interpolation_indices(center_index, len(inputs_set), gap)\n",
        "        if idx1 is None:\n",
        "            print(f\"Skipping index {center_index} (gap={gap}) due to limits.\")\n",
        "            continue\n",
        "\n",
        "        x1, x2, x3 = in_test[idx1], in_test[idx2], in_test[idx3]\n",
        "        y1, y2_true, y3 = out_test[idx1], out_test[idx2], out_test[idx3]\n",
        "\n",
        "        # predict y2 with the trained NN\n",
        "        x_tensor = torch.FloatTensor(x2).unsqueeze(0).to(device)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y2_pred = model(x_tensor).cpu().numpy()[0]\n",
        "\n",
        "        # Denormalize and inverse log transform\n",
        "        P_true = 10 ** np.array([y1[0], y2_true[0], y3[0]])\n",
        "        S_true = 10 ** np.array([y1[1], y2_true[1], y3[1]])\n",
        "        P_pred = inv_log_scaled([y2_pred[0]], scaler_P)[0]\n",
        "        S_pred = inv_log_scaled([y2_pred[1]], scaler_S)[0]\n",
        "\n",
        "        # Metrics\n",
        "        mse_P = mean_squared_error([P_true[1]], [P_pred])\n",
        "        mae_P = mean_absolute_error([P_true[1]], [P_pred])\n",
        "        mse_S = mean_squared_error([S_true[1]], [S_pred])\n",
        "        mae_S = mean_absolute_error([S_true[1]], [S_pred])\n",
        "        metrics.append({\"method\": \"NN\", \"index\": int(center_index), \"mse_P\": mse_P, \"mae_P\": mae_P, \"mse_S\": mse_S, \"mae_S\": mae_S})\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        for m in metrics:\n",
        "            m[\"elapsed_sec\"] = elapsed\n",
        "\n",
        "        # Plots\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        x_labels = [f'Idx {idx1}', f'Idx {idx2}', f'Idx {idx3}']\n",
        "        x_ticks = np.arange(3)\n",
        "\n",
        "        axs[0].plot(x_ticks, P_true, label='True P', marker='o', color='green')\n",
        "        axs[0].scatter(x_ticks[1], P_pred, label='Predicted P', marker='x', s=100, color='red')\n",
        "        axs[0].set_title('Pressure (P)', fontsize=14)\n",
        "        axs[0].set_xticks(x_ticks)\n",
        "        axs[0].tick_params(axis='y', labelsize=14)\n",
        "        axs[0].set_xticklabels(x_labels, fontsize=14)\n",
        "        axs[0].grid(True)\n",
        "        axs[0].legend(fontsize=14)\n",
        "        axs[0].ticklabel_format(axis='y', style='sci', scilimits=(-3, 3))\n",
        "\n",
        "        axs[1].plot(x_ticks, S_true, label='True S', marker='o', color='blue')\n",
        "        axs[1].scatter(x_ticks[1], S_pred, label='Predicted S', marker='x', s=100, color='orange')\n",
        "        axs[1].set_title('Entropy (S)', fontsize=14)\n",
        "        axs[1].set_xticks(x_ticks)\n",
        "        axs[1].tick_params(axis='y', labelsize=14)\n",
        "        axs[1].set_xticklabels(x_labels, fontsize=14)\n",
        "        axs[1].grid(True)\n",
        "        axs[1].legend(fontsize=14)\n",
        "        axs[1].ticklabel_format(axis='y', style='sci', scilimits=(-3, 3))\n",
        "\n",
        "        plt.suptitle(f\"NN Interpolation Triplet Test #{i+1} (Index {center_index})\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        filename = f\"NN_triplet_{i+1}_index_{center_index}.png\"\n",
        "        plt.savefig(os.path.join(save_dir, filename), dpi=300)\n",
        "        plt.close()\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH2Ev5DdyKng"
      },
      "outputs": [],
      "source": [
        "#######################################################\n",
        "# b-SPLINES INTERPOLATION\n",
        "#######################################################\n",
        "def interpolation_test_bspline(in_train, out_train, in_test, out_test, indices, save_dir, gap=1):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    x, y = in_train[:, 0], in_train[:, 1]\n",
        "    z_P, z_S = out_train[:, 0], out_train[:, 1]\n",
        "\n",
        "    # Create the cubic Bspline based on training data\n",
        "    bspline_P = SmoothBivariateSpline(x, y, z_P, kx=3, ky=3)\n",
        "    bspline_S = SmoothBivariateSpline(x, y, z_S, kx=3, ky=3)\n",
        "\n",
        "    metrics = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, center_index in enumerate(indices):\n",
        "        idx1, idx2, idx3 = get_interpolation_indices(center_index, len(in_test), gap)\n",
        "\n",
        "        if idx1 is None:\n",
        "            print(f\"Saltando índice {center_index} (gap={gap}) debido a límites.\")\n",
        "            continue\n",
        "\n",
        "        x1, x2, x3 = in_test[idx1], in_test[idx2], in_test[idx3]\n",
        "        y1, y2_true, y3 = out_test[idx1], out_test[idx2], out_test[idx3]\n",
        "\n",
        "        # Predictions for y2\n",
        "        P_pred_log = bspline_P.ev(x2[0], x2[1])\n",
        "        S_pred_log = bspline_S.ev(x2[0], x2[1])\n",
        "\n",
        "        # Inverse log transform\n",
        "        P_true = 10 ** np.array([y1[0], y2_true[0], y3[0]])\n",
        "        S_true = 10 ** np.array([y1[1], y2_true[1], y3[1]])\n",
        "        P_pred = 10 ** P_pred_log\n",
        "        S_pred = 10 ** S_pred_log\n",
        "\n",
        "        # Metrics\n",
        "        mse_P = mean_squared_error([P_true[1]], [P_pred])\n",
        "        mae_P = mean_absolute_error([P_true[1]], [P_pred])\n",
        "        mse_S = mean_squared_error([S_true[1]], [S_pred])\n",
        "        mae_S = mean_absolute_error([S_true[1]], [S_pred])\n",
        "        metrics.append({\"method\": \"B-Spline\", \"index\": int(center_index), \"mse_P\": mse_P, \"mae_P\": mae_P, \"mse_S\": mse_S, \"mae_S\": mae_S})\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        for m in metrics:\n",
        "            m[\"elapsed_sec\"] = elapsed\n",
        "\n",
        "        # Plot\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        x_labels = [f'Idx {idx1}', f'Idx {idx2}', f'Idx {idx3}']\n",
        "        x_ticks = np.arange(3)\n",
        "\n",
        "        axs[0].plot(x_ticks, P_true, label='True P', marker='o', color='green')\n",
        "        axs[0].scatter(x_ticks[1], P_pred, label='Predicted P', marker='x', s=100, color='red')\n",
        "        axs[0].set_title('Pressure (P)', fontsize=14)\n",
        "        axs[0].set_xticks(x_ticks)\n",
        "        axs[0].set_xticklabels(x_labels, fontsize=14)\n",
        "        axs[0].tick_params(axis='y', labelsize=14)\n",
        "        axs[0].grid(True)\n",
        "        axs[0].legend(fontsize=14)\n",
        "        axs[0].ticklabel_format(axis='y', style='sci', scilimits=(-3, 3))\n",
        "\n",
        "        axs[1].plot(x_ticks, S_true, label='True S', marker='o', color='blue')\n",
        "        axs[1].scatter(x_ticks[1], S_pred, label='Predicted S', marker='x', s=100, color='orange')\n",
        "        axs[1].set_title('Entropy (S)', fontsize=14)\n",
        "        axs[1].set_xticks(x_ticks)\n",
        "        axs[1].tick_params(axis='y', labelsize=14)\n",
        "        axs[1].set_xticklabels(x_labels, fontsize=14)\n",
        "        axs[1].grid(True)\n",
        "        axs[1].legend(fontsize=14)\n",
        "        axs[1].ticklabel_format(axis='y', style='sci', scilimits=(-3, 3))\n",
        "\n",
        "        plt.suptitle(f\"B-Spline Interpolation Triplet Test #{i+1} (Index {center_index})\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        filename = f\"SPLINE_triplet_{i+1}_index_{center_index}.png\"\n",
        "        plt.savefig(os.path.join(save_dir, filename), dpi=300)\n",
        "        plt.close()\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the model and instantiate\n",
        "top_path = #path where top model is saved\n",
        "config_path = os.path.join(top_path, \"config.json\")\n",
        "weights_path = os.path.join(top_path, \"model_top1.pth\")\n",
        "\n",
        "def load_model_from_config(config_path, in_size, out_size):\n",
        "    with open(config_path, \"r\") as f:\n",
        "        config = json.load(f)\n",
        "    hidden_layer_sizes = config.get(\"hidden_layer_sizes\")\n",
        "    dropout = config.get(\"dropout\")\n",
        "    activation_str = config.get(\"activation_fn\")\n",
        "    activation_cls = load_activation_fn(activation_str)\n",
        "\n",
        "    model = Interpolation(in_size, out_size, hidden_layer_sizes, dropout, activation_cls)\n",
        "    return model\n",
        "\n",
        "in_size, out_size = 2, 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = load_model_from_config(config_path, in_size, out_size)\n",
        "model.load_state_dict(torch.load(weights_path, map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "# 5 random index for both methods\n",
        "max_index = len(in_test)\n",
        "indices = random.sample(range(max_index), 5)\n",
        "print(indices)\n",
        "\n",
        "dir_nn = # path for saving nn interpolation\n",
        "os.makedirs(dir_nn, exist_ok=True)\n",
        "dir_spl = #path for saving bsplines interpolation\n",
        "os.makedirs(dir_spl, exist_ok=True)"
      ],
      "metadata": {
        "id": "7wGtOpxncK9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWVpN2A6ywPu"
      },
      "outputs": [],
      "source": [
        "# 1. NN interpolation\n",
        "metrics_nn = interpolation_test_nn(model=model, inputs_set=in_test, outputs_set=out_test, scaler_P=scaler_P, scaler_S=scaler_S, device=device, indices=indices, save_dir=dir_nn)\n",
        "for metric in metrics_nn:\n",
        "    print(metric)\n",
        "\n",
        "# 2. B-Spline interpolation\n",
        "metrics_spline = interpolation_test_bspline(in_train=in_train, out_train=out_train, in_test=in_test, out_test=out_test, indices=indices, save_dir=dir_spl)\n",
        "for metric in metrics_spline:\n",
        "    print(metric)\n",
        "\n",
        "# 3. Save metrics\n",
        "save_dir = # path to save metrics\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "df_all = pd.DataFrame(metrics_nn + metrics_spline)\n",
        "csv_path = os.path.join(dir_nn, \"interpolation_metrics_comparison.csv\")\n",
        "df_all.to_csv(csv_path, index=False)"
      ]
    }
  ]
}